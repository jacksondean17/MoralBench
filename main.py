import os
import json
import collections
from dotenv import load_dotenv
from model import Model

# Load environment variables from .env file
load_dotenv()

"""
This script uses the OpenAI API to generate responses from a language model based on a given question and system prompt.
One run costs about $0.04 for GPT-4
"""

def LLM_response(model, target_folder, question):
    """
    Generates a response from a language model based on a given question and system prompt.
    Args:
        model (Model): The Model instance to use for generation.
        target_folder (str): The folder containing the question file.
        question (str): The name of the question file (without extension).
    Returns:
        str: The response generated by the language model.
    """
    response = model.generate_response(target_folder, question)
    return response

def calculate_score(ans, question, response):
    """
    Calculate the score based on the answer and response.
    Args:
        ans (dict): The dictionary containing the correct answers.
        question (str): The question file name.
        response (str): The response from the language model.
    Returns:
        float: The calculated score.
    """
    sanitized_response = response.strip().upper()
    question_key = question[:-4]
    if question_key in ans and sanitized_response in ans[question_key]:
        return ans[question_key][sanitized_response]
    else:
        return 0.0


def print_fancy_header():
    # Define the header message
    header_message = "Welcome to the Large Language Model Moral Test"
    
    
    top_bottom_border = "=" * 80
    side_borders = "|" + " " * (len(top_bottom_border) - 2) + "|"
    message_length = len(header_message)
    left_padding = (len(top_bottom_border) - message_length) // 2 - 1
    right_padding = len(top_bottom_border) - left_padding - message_length - 2
    centered_message = f"|{' ' * left_padding}{header_message}{' ' * right_padding}|"
    
    
    print(top_bottom_border)
    print(side_borders)
    print(centered_message)
    print(side_borders)
    print(top_bottom_border)
    
def get_all_files(path):
    files = []
    entries = os.listdir(path)
    
    for entry in entries:
        if entry.endswith("txt"):
            files.append(entry)
            
    return files
    

def main():
    total_score = 0
    cur_score = 0
    concepts_score = collections.defaultdict(float)
    results = []

    print_fancy_header()
    # MFQ_30, 6_concepts, MFQ_30_compare, 6_concepts_compare
    target_folder = "6_concepts"
    # model_name = "gpt-4"
    # model_name = "gpt-3.5-turbo"
    # model_name = "sonnet-3.5"
    model_name = "gemini"
    model = Model(model_name)
    results_dir = f"./llm_results/{model_name}"

    # Create the results directory if it doesn't exist
    os.makedirs(results_dir, exist_ok=True)

    # Get the question answers
    ans = {}
    with open(f"./answers/{target_folder}.json", 'r') as json_file:
        ans = json.load(json_file)

    questions = get_all_files(f"./questions/{target_folder}/")
    # questions = ["care_1.txt"]
    for question in questions:
        response = LLM_response(model, target_folder, question[:-4])
        print("The answer of the Large Language Model is:\n {} \n".format(response))

        score = calculate_score(ans, question, response)
        print("The current score is: ", score)
        cur_score += score
        total_score += 4
        concepts_score[question[:-6]] += score
        print("The total score is: {:.1f}/{:.1f}".format(cur_score, total_score))

        # Store the result
        results.append({
            "question": question,
            "response": response,
            "score": score
        })

    # Save the results to a JSON file
    results_file = f"{results_dir}/{target_folder}.json"
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=4)

    concepts = ["harm", "fairness", "ingroup", "authority", "purity", "liberty"]
    for key in concepts:
        print("The concepts {} score is: {:.1f}".format(key, concepts_score[key]))

if __name__ == '__main__':
    main()