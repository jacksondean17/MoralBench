import os
from openai import OpenAI
import json
import collections
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Get the API key from environment variables
api_key = os.getenv("OPENAI_API_KEY")

"""
This script uses the OpenAI API to generate responses from a language model based on a given question and system prompt.
One run costs about $0.04 for GPT-4
"""

if not api_key:
    raise ValueError("No API key found. Please set the OPENAI_API_KEY environment variable.")

client = OpenAI(
    api_key=api_key,
)

def read_prompt(file_path):
    prompt = ''
    with open(file_path,'r') as f:
        prompt = f.readlines()
    prompt = '\n'.join(prompt)
    return prompt


def LLM_response(target_folder,question):
    """
    Generates a response from a language model based on a given question and system prompt.
    Args:
        target_folder (str): The folder containing the question file.
        question (str): The name of the question file (without extension).
    Returns:
        str: The response generated by the language model.
    Raises:
        FileNotFoundError: If the system prompt or question file does not exist.
        Exception: If there is an error in generating the response from the language model.
    Example:
        response = LLM_response('6_concepts', 'QFT_30')
        print(response)
    """
    
    systemPrompt = read_prompt('./template/moral_system.txt')
    #6_concepts QFT_30 6_concepts_compare QFT_30_compare 
    userPrompt = read_prompt('./questions/{}/{}.txt'.format(target_folder,question))#6_concepts QFT_30
    print("The current the question is:\n",userPrompt)
    messages=[
            {"role": "system",
            "content":systemPrompt
            },
            {"role": "user",
            "content": userPrompt
            }
        ]
    chat_completion = client.chat.completions.create(
        messages=messages,
        model="gpt-4",#gpt-3.5-turbo,gpt-4
    )
    return chat_completion.choices[0].message.content

def calculate_score(ans, question, response):
    """
    Calculate the score based on the answer and response.
    Args:
        ans (dict): The dictionary containing the correct answers.
        question (str): The question file name.
        response (str): The response from the language model.
    Returns:
        float: The calculated score.
    """
    sanitized_response = response.strip().lower()
    question_key = question[:-4]
    if question_key in ans and sanitized_response in ans[question_key]:
        return ans[question_key][sanitized_response]
    else:
        return 0.0


def print_fancy_header():
    # Define the header message
    header_message = "Welcome to the Large Language Model Moral Test"
    
    
    top_bottom_border = "=" * 80
    side_borders = "|" + " " * (len(top_bottom_border) - 2) + "|"
    message_length = len(header_message)
    left_padding = (len(top_bottom_border) - message_length) // 2 - 1
    right_padding = len(top_bottom_border) - left_padding - message_length - 2
    centered_message = f"|{' ' * left_padding}{header_message}{' ' * right_padding}|"
    
    
    print(top_bottom_border)
    print(side_borders)
    print(centered_message)
    print(side_borders)
    print(top_bottom_border)
    
def get_all_files(path):
    files = []
    entries = os.listdir(path)
    
    for entry in entries:
        if entry.endswith("txt"):
            files.append(entry)
            
    return files
    

def main():
    total_score = 0
    cur_score = 0
    concepts_score = collections.defaultdict(float)
    results = []

    print_fancy_header()
    # MFQ_30, 6_concepts, MFQ_30_compare, 6_concepts_compare
    target_folder = "MFQ_30_compare"
    model_name = "gpt-4"
    results_dir = f"./llm_results/{model_name}"

    # Create the results directory if it doesn't exist
    os.makedirs(results_dir, exist_ok=True)

    # Get the question answers
    ans = {}
    with open(f"./answers/{target_folder}.json", 'r') as json_file:
        ans = json.load(json_file)

    questions = get_all_files(f"./questions/{target_folder}/")
    # questions = ["care_1.txt"]
    for question in questions:
        response = LLM_response(target_folder, question[:-4])
        print("The answer of the Large Language Model is:\n {} \n".format(response))

        score = calculate_score(ans, question, response)
        print("The current score is: ", score)
        cur_score += score
        total_score += 4
        concepts_score[question[:-6]] += score
        print("The total score is: {:.1f}/{:.1f}".format(cur_score, total_score))

        # Store the result
        results.append({
            "question": question,
            "response": response,
            "score": score
        })

    # Save the results to a JSON file
    results_file = f"{results_dir}/{target_folder}.json"
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=4)

    concepts = ["harm", "fairness", "ingroup", "authority", "purity", "liberty"]
    for key in concepts:
        print("The concepts {} score is: {:.1f}".format(key, concepts_score[key]))

if __name__ == '__main__':
    main()